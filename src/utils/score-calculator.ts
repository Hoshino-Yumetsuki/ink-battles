interface DimensionScore {
  name: string
  score: number
  description: string
  confidence?: number
  variance?: number
}

interface QualityMetrics {
  consistency: number
  reliability: number
  objectivity: number
  completeness: number
}

interface AdvancedScoreResult {
  finalScore: number
  baseScore: number
  adjustments: Record<string, number>
  qualityMetrics: QualityMetrics
}

const DIMENSION_WEIGHTS: Record<string, number> = {
  'ğŸ­ äººç‰©å¡‘é€ åŠ›': 1.2,
  'ğŸ§  ç»“æ„å¤æ‚åº¦': 1.0,
  'ğŸ”€ æƒ…èŠ‚åè½¬å¯†åº¦': 0.9,
  'ğŸ’” æƒ…æ„Ÿç©¿é€åŠ›': 1.1,
  'ğŸ¨ æ–‡ä½“é­…åŠ›': 1.0,
  'ğŸŒ€ å…ˆé”‹æ€§/å®éªŒæ€§': 0.8,
  'ğŸ˜‚ å¹½é»˜æ„Ÿ/è‡ªå˜²åŠ›': 0.7,
  'ğŸŒ ä¸»é¢˜æ·±åº¦': 1.2,
  'ğŸº æ–‡åŒ–åº•è•´æ€§': 1.0,
  'ğŸ“š å¼•ç”¨å¼ åŠ›ï¼ˆäº’æ–‡æ€§ï¼‰': 0.8,
  'ğŸª¤ è°œå›¢æ“æ§åŠ›ä¸è¯»è€…è¯±å¯¼æ€§': 0.9,
  'ğŸ§· ç¨³å®šæ€§/å®Œæˆåº¦': 1.0,
  'ğŸ§¬ è¯­è¨€åŸåˆ›æ€§': 1.1,
  'ğŸ‘‘ ç»å…¸æ€§': 1.2,
  'ğŸ§‘â€ğŸš€ æ–°é”æ€§': 0.9
}

const OPTIONAL_DIMENSIONS = new Set([
  'ğŸ˜‚ å¹½é»˜æ„Ÿ/è‡ªå˜²åŠ›',
  'ğŸ“š å¼•ç”¨å¼ åŠ›ï¼ˆäº’æ–‡æ€§ï¼‰',
  'ğŸª¤ è°œå›¢æ“æ§åŠ›ä¸è¯»è€…è¯±å¯¼æ€§',
  'ğŸ”€ æƒ…èŠ‚åè½¬å¯†åº¦'
])

const SCORE_CONFIG = {
  MIN_SCORE: 0,
  MIN_BASE_SCORE: 15,
  MAX_BASE_SCORE: 120,
  EXCELLENCE_THRESHOLD: 4.0,
  SYNERGY_FACTOR: 0.7,
  BALANCE_BONUS: 1.0,
  BREAKTHROUGH_THRESHOLD: 110,
  CONSISTENCY_THRESHOLD: 0.7,
  RELIABILITY_THRESHOLD: 0.8,
  OBJECTIVITY_WEIGHT: 0.15,
  VARIANCE_PENALTY_FACTOR: 0.08,
  CONFIDENCE_BOOST_FACTOR: 0.07
}

const DYNAMIC_WEIGHT_CONFIG = {
  QUALITY_BASED_ADJUSTMENT: 0.2,
  CORRELATION_THRESHOLD: 0.6,
  ADAPTIVE_FACTOR: 0.1
}

const SYNERGY_GROUPS: Record<string, string[]> = {
  åˆ›ä½œæ ¸å¿ƒ: ['ğŸ­ äººç‰©å¡‘é€ åŠ›', 'ğŸ§  ç»“æ„å¤æ‚åº¦', 'ğŸ’” æƒ…æ„Ÿç©¿é€åŠ›'],
  æƒ…æ„Ÿè¡¨è¾¾: ['ğŸ’” æƒ…æ„Ÿç©¿é€åŠ›', 'ğŸ¨ æ–‡ä½“é­…åŠ›', 'ğŸ˜‚ å¹½é»˜æ„Ÿ/è‡ªå˜²åŠ›'],
  æ·±åº¦å†…æ¶µ: ['ğŸŒ ä¸»é¢˜æ·±åº¦', 'ğŸº æ–‡åŒ–åº•è•´æ€§', 'ğŸ“š å¼•ç”¨å¼ åŠ›ï¼ˆäº’æ–‡æ€§ï¼‰'],
  åˆ›æ–°å®éªŒ: ['ğŸŒ€ å…ˆé”‹æ€§/å®éªŒæ€§', 'ğŸ§¬ è¯­è¨€åŸåˆ›æ€§', 'ğŸ§‘â€ğŸš€ æ–°é”æ€§'],
  å®Œæˆå“è´¨: ['ğŸ§· ç¨³å®šæ€§/å®Œæˆåº¦', 'ğŸ¨ æ–‡ä½“é­…åŠ›', 'ğŸ§¬ è¯­è¨€åŸåˆ›æ€§'],
  ç»å…¸ä»·å€¼: ['ğŸ‘‘ ç»å…¸æ€§', 'ğŸŒ ä¸»é¢˜æ·±åº¦', 'ğŸº æ–‡åŒ–åº•è•´æ€§'],
  å™äº‹æŠ€å·§: ['ğŸ”€ æƒ…èŠ‚åè½¬å¯†åº¦', 'ğŸª¤ è°œå›¢æ“æ§åŠ›ä¸è¯»è€…è¯±å¯¼æ€§', 'ğŸ§  ç»“æ„å¤æ‚åº¦']
}

export function calculateOverallScore(
  dimensions: DimensionScore[] | Record<string, any>
): number {
  const result = calculateAdvancedScore(dimensions)
  return result.finalScore
}

export function calculateDetailedScore(
  dimensions: DimensionScore[] | Record<string, any>
): AdvancedScoreResult {
  return calculateAdvancedScore(dimensions)
}

export function calculateAdvancedScore(
  dimensions: DimensionScore[] | Record<string, any>
): AdvancedScoreResult {
  if (!dimensions) {
    return createEmptyResult()
  }

  let dimensionArray: DimensionScore[]
  if (!Array.isArray(dimensions)) {
    dimensionArray = []
    Object.entries(dimensions).forEach(([key, value]) => {
      if (typeof value === 'object' && value !== null) {
        const dimensionScore = typeof value.score === 'number' ? value.score : 0
        dimensionArray.push({
          name: key,
          score: dimensionScore,
          description: value.description || '',
          confidence: value.confidence || 0.8,
          variance: value.variance || 0.1
        })
      }
    })
  } else {
    dimensionArray = dimensions.map((dim) => ({
      ...dim,
      confidence: dim.confidence || 0.8,
      variance: dim.variance || 0.1
    }))
  }

  if (dimensionArray.length === 0) {
    return createEmptyResult()
  }

  return calculateAdvancedComplexScore(dimensionArray)
}

function createEmptyResult(): AdvancedScoreResult {
  return {
    finalScore: SCORE_CONFIG.MIN_SCORE,
    baseScore: SCORE_CONFIG.MIN_SCORE,
    adjustments: {},
    qualityMetrics: {
      consistency: 0,
      reliability: 0,
      objectivity: 0,
      completeness: 0
    }
  }
}

function calculateAdvancedComplexScore(
  dimensions: DimensionScore[]
): AdvancedScoreResult {
  const validDimensions = filterValidDimensions(dimensions)

  if (validDimensions.length === 0) {
    return createEmptyResult()
  }

  const qualityMetrics = calculateQualityMetrics(validDimensions)

  const adjustedWeights = calculateDynamicWeights(
    validDimensions,
    qualityMetrics
  )

  const baseScore = calculateAdvancedBaseScore(validDimensions, adjustedWeights)

  const adjustments: Record<string, number> = {}

  adjustments.synergyBonus = calculateSynergyBonus(validDimensions)
  adjustments.excellenceBonus = calculateExcellenceBonus(validDimensions)
  adjustments.balanceAdjustment = calculateBalanceAdjustment(validDimensions)
  adjustments.qualityPenalty = calculateQualityPenalty(validDimensions)
  adjustments.consistencyAdjustment = calculateConsistencyAdjustment(
    validDimensions,
    qualityMetrics
  )
  adjustments.objectivityBonus = calculateObjectivityBonus(
    validDimensions,
    qualityMetrics
  )

  let totalScore =
    baseScore + Object.values(adjustments).reduce((sum, adj) => sum + adj, 0)

  if (totalScore > SCORE_CONFIG.BREAKTHROUGH_THRESHOLD) {
    totalScore = applyBreakthroughConstraint(totalScore, validDimensions)
  }

  totalScore = Math.max(totalScore, SCORE_CONFIG.MIN_SCORE)

  return {
    finalScore: Number(totalScore.toFixed(1)),
    baseScore: Number(baseScore.toFixed(1)),
    adjustments,
    qualityMetrics
  }
}

function filterValidDimensions(dimensions: DimensionScore[]): DimensionScore[] {
  return dimensions.filter(
    (dimension) =>
      dimension &&
      typeof dimension === 'object' &&
      typeof dimension.name === 'string' &&
      typeof dimension.score === 'number' &&
      !Number.isNaN(dimension.score) &&
      dimension.score >= 0
  )
}

function calculateSynergyBonus(dimensions: DimensionScore[]): number {
  let totalSynergy = 0
  const dimensionMap = new Map<string, number>()

  dimensions.forEach((dim) => {
    dimensionMap.set(dim.name, dim.score)
  })

  Object.entries(SYNERGY_GROUPS).forEach(([_groupName, dimensionNames]) => {
    const groupScores = dimensionNames
      .map((name) => dimensionMap.get(name) || 0)
      .filter((score) => score > 0)

    const totalDimensionsInGroup = dimensionNames.length
    const optionalCount = dimensionNames.filter((name) =>
      OPTIONAL_DIMENSIONS.has(name)
    ).length
    const requiredForSynergy = Math.max(
      2,
      Math.ceil((totalDimensionsInGroup - optionalCount) * 0.6)
    )

    if (groupScores.length >= requiredForSynergy) {
      const geometricMean =
        groupScores.reduce((acc, score) => acc * Math.max(1, score), 1) **
        (1 / groupScores.length)

      const participationRatio = groupScores.length / totalDimensionsInGroup
      const synergyMultiplier = 0.7 + participationRatio * 0.3

      if (geometricMean > 7) {
        const synergyContribution =
          (geometricMean - 6) *
          SCORE_CONFIG.SYNERGY_FACTOR *
          groupScores.length *
          synergyMultiplier
        totalSynergy += synergyContribution
      }
    }
  })

  return Math.min(totalSynergy, 15)
}

function calculateExcellenceBonus(dimensions: DimensionScore[]): number {
  const excellentDimensions = dimensions.filter(
    (dim) => dim.score >= SCORE_CONFIG.EXCELLENCE_THRESHOLD
  )

  if (excellentDimensions.length < 3) {
    return 0
  }

  const excellenceCount = excellentDimensions.length
  const avgExcellenceScore =
    excellentDimensions.reduce((sum, dim) => sum + dim.score, 0) /
    excellenceCount

  const bonus =
    (excellenceCount / dimensions.length) ** 1.3 *
    (avgExcellenceScore - SCORE_CONFIG.EXCELLENCE_THRESHOLD) *
    2.2

  return Math.min(bonus, 18)
}
function calculateBalanceAdjustment(dimensions: DimensionScore[]): number {
  const coreScores = dimensions
    .filter((dim) => !OPTIONAL_DIMENSIONS.has(dim.name))
    .map((dim) => dim.score)
  const optionalScores = dimensions
    .filter((dim) => OPTIONAL_DIMENSIONS.has(dim.name) && dim.score > 0)
    .map((dim) => dim.score)

  if (coreScores.length < 4) {
    return -8
  }

  const coreMean =
    coreScores.reduce((sum, score) => sum + score, 0) / coreScores.length
  const coreVariance =
    coreScores.reduce((sum, score) => sum + (score - coreMean) ** 2, 0) /
    coreScores.length
  const coreStdDev = Math.sqrt(coreVariance)

  const coreBalanceBonus = Math.max(
    0,
    (3 - coreStdDev) * SCORE_CONFIG.BALANCE_BONUS * coreMean * 0.1
  )

  const optionalBonus =
    optionalScores.length > 0 ? Math.min(1.8, optionalScores.length * 0.6) : 0

  const maxCoreScore = Math.max(...coreScores)
  const minCoreScore = Math.min(...coreScores)
  const extremeGap = maxCoreScore - minCoreScore
  const extremePenalty = extremeGap > 8 ? -(extremeGap - 8) * 0.3 : 0

  const totalAdjustment = coreBalanceBonus + optionalBonus + extremePenalty
  return Math.max(-10, Math.min(totalAdjustment, 12))
}

function calculateQualityPenalty(dimensions: DimensionScore[]): number {
  const avgScore =
    dimensions.reduce((sum, dim) => sum + dim.score, 0) / dimensions.length

  const highScoreDimensions = dimensions.filter(
    (dim) => dim.score >= 4.0
  ).length
  const excellentDimensions = dimensions.filter(
    (dim) => dim.score >= 4.5
  ).length

  const veryLowScoreDimensions = dimensions.filter(
    (dim) => dim.score <= 1.5
  ).length
  const veryLowScoreRatio = veryLowScoreDimensions / dimensions.length

  const lowScoreDimensions = dimensions.filter((dim) => dim.score <= 2.5).length
  const lowScoreRatio = lowScoreDimensions / dimensions.length

  let penaltyReduction = 0
  if (highScoreDimensions >= 4) {
    penaltyReduction = 0.8
  } else if (highScoreDimensions >= 2) {
    penaltyReduction = 0.5
  } else if (excellentDimensions >= 1) {
    penaltyReduction = 0.3
  }

  let basePenalty = 0
  if (avgScore <= 1.2 && veryLowScoreRatio >= 0.9) {
    basePenalty = -15
  } else if (avgScore <= 1.5 && veryLowScoreRatio >= 0.8) {
    basePenalty = -8
  } else if (avgScore <= 2.0 && lowScoreRatio >= 0.8) {
    basePenalty = -4
  } else if (avgScore <= 2.5 && lowScoreRatio >= 0.6) {
    basePenalty = -1
  }

  return basePenalty * (1 - penaltyReduction)
}

function applyBreakthroughConstraint(
  score: number,
  dimensions: DimensionScore[]
): number {
  const highScoreDimensions = dimensions.filter((dim) => dim.score >= 4).length
  const veryHighScoreDimensions = dimensions.filter(
    (dim) => dim.score >= 4.5
  ).length
  const excellentDimensions = dimensions.filter((dim) => dim.score >= 5).length

  if (highScoreDimensions >= 10 || excellentDimensions >= 3) {
    const excess = score - SCORE_CONFIG.BREAKTHROUGH_THRESHOLD
    return SCORE_CONFIG.BREAKTHROUGH_THRESHOLD + excess * 0.95
  } else if (highScoreDimensions >= 8 || veryHighScoreDimensions >= 3) {
    const excess = score - SCORE_CONFIG.BREAKTHROUGH_THRESHOLD
    return SCORE_CONFIG.BREAKTHROUGH_THRESHOLD + excess * 0.9
  } else if (highScoreDimensions >= 6 || excellentDimensions >= 2) {
    const excess = score - SCORE_CONFIG.BREAKTHROUGH_THRESHOLD
    return SCORE_CONFIG.BREAKTHROUGH_THRESHOLD + excess * 0.85
  } else if (highScoreDimensions >= 4) {
    const excess = score - SCORE_CONFIG.BREAKTHROUGH_THRESHOLD
    return SCORE_CONFIG.BREAKTHROUGH_THRESHOLD + excess * 0.8
  } else {
    return Math.min(score, SCORE_CONFIG.BREAKTHROUGH_THRESHOLD)
  }
}

function calculateQualityMetrics(dimensions: DimensionScore[]): QualityMetrics {
  const scores = dimensions.map((d) => d.score)
  const confidences = dimensions.map((d) => d.confidence || 0.8)
  const variances = dimensions.map((d) => d.variance || 0.1)

  const scoreMean = scores.reduce((sum, s) => sum + s, 0) / scores.length
  const scoreVariance =
    scores.reduce((sum, s) => sum + (s - scoreMean) ** 2, 0) / scores.length
  const consistency =
    Math.max(0, 1 - scoreVariance / 4) * 0.7 +
    (confidences.reduce((sum, c) => sum + c, 0) / confidences.length) * 0.3

  const avgConfidence =
    confidences.reduce((sum, c) => sum + c, 0) / confidences.length
  const completenessRatio =
    dimensions.length / Object.keys(DIMENSION_WEIGHTS).length
  const reliability = avgConfidence * 0.6 + completenessRatio * 0.4

  const avgVariance =
    variances.reduce((sum, v) => sum + v, 0) / variances.length
  const scoreDistribution = calculateScoreDistribution(scores)
  const objectivity =
    Math.max(0, 1 - avgVariance) * 0.5 + scoreDistribution * 0.5

  const corePresent = dimensions.filter(
    (d) => !OPTIONAL_DIMENSIONS.has(d.name)
  ).length
  const totalCore =
    Object.keys(DIMENSION_WEIGHTS).length - OPTIONAL_DIMENSIONS.size
  const completeness =
    Math.min(1, corePresent / totalCore) * 0.8 + completenessRatio * 0.2

  return {
    consistency: Number(consistency.toFixed(3)),
    reliability: Number(reliability.toFixed(3)),
    objectivity: Number(objectivity.toFixed(3)),
    completeness: Number(completeness.toFixed(3))
  }
}

function calculateScoreDistribution(scores: number[]): number {
  const bins = [0, 1, 2, 3, 4, 5]
  const distribution = new Array(bins.length - 1).fill(0)

  scores.forEach((score) => {
    for (let i = 0; i < bins.length - 1; i++) {
      if (score >= bins[i] && score < bins[i + 1]) {
        distribution[i]++
        break
      }
    }
  })

  const total = scores.length
  let entropy = 0
  distribution.forEach((count) => {
    if (count > 0) {
      const p = count / total
      entropy -= p * Math.log2(p)
    }
  })

  const maxEntropy = Math.log2(distribution.length)
  return entropy / maxEntropy
}

function calculateDynamicWeights(
  dimensions: DimensionScore[],
  qualityMetrics: QualityMetrics
): Record<string, number> {
  const adjustedWeights: Record<string, number> = { ...DIMENSION_WEIGHTS }

  dimensions.forEach((dimension) => {
    const baseName = dimension.name
    const baseWeight = DIMENSION_WEIGHTS[baseName] || 1.0

    let qualityAdjustment = 1.0

    if (dimension.score >= 4.5) {
      qualityAdjustment += DYNAMIC_WEIGHT_CONFIG.QUALITY_BASED_ADJUSTMENT
    } else if (dimension.score <= 2.0) {
      qualityAdjustment -= DYNAMIC_WEIGHT_CONFIG.QUALITY_BASED_ADJUSTMENT * 0.5
    }

    const confidenceAdjustment = (dimension.confidence || 0.8) * 0.2 + 0.8

    const consistencyAdjustment = qualityMetrics.consistency * 0.1 + 0.9

    adjustedWeights[baseName] =
      baseWeight *
      qualityAdjustment *
      confidenceAdjustment *
      consistencyAdjustment
  })

  return adjustedWeights
}

function calculateAdvancedBaseScore(
  dimensions: DimensionScore[],
  adjustedWeights: Record<string, number>
): number {
  let weightedSum = 0
  let totalWeight = 0
  let totalQualityScore = 0
  let dimensionCount = 0

  dimensions.forEach((dimension) => {
    const weight = adjustedWeights[dimension.name] || 1.0
    const confidence = dimension.confidence || 0.8

    totalQualityScore += dimension.score
    dimensionCount++

    let scaledScore = mapScoreNonLinear(dimension.score)

    scaledScore *= 0.7 + confidence * 0.3

    const cappedScore = Math.min(32, scaledScore)

    weightedSum += cappedScore * weight
    totalWeight += weight
  })

  const averageScore = weightedSum / totalWeight
  const avgQuality = totalQualityScore / dimensionCount

  const qualityRatio = Math.max(0, Math.min(1, (avgQuality - 1) / 4))
  const dynamicBaseScore =
    SCORE_CONFIG.MIN_BASE_SCORE +
    (SCORE_CONFIG.MAX_BASE_SCORE - SCORE_CONFIG.MIN_BASE_SCORE) * qualityRatio

  return dynamicBaseScore + averageScore * 1.5
}

function mapScoreNonLinear(score: number): number {
  if (score >= 4.5) {
    return 22 + (score - 4.5) * 12
  } else if (score >= 4.0) {
    return 18 + (score - 4.0) * 8
  } else if (score >= 3.0) {
    return 11 + (score - 3.0) * 7
  } else if (score >= 2.0) {
    return 6 + (score - 2.0) * 5
  } else {
    return Math.log(Math.max(0.1, score) + 1) * 4
  }
}

function calculateConsistencyAdjustment(
  _dimensions: DimensionScore[],
  qualityMetrics: QualityMetrics
): number {
  const consistencyScore = qualityMetrics.consistency

  if (consistencyScore >= SCORE_CONFIG.CONSISTENCY_THRESHOLD) {
    return (consistencyScore - SCORE_CONFIG.CONSISTENCY_THRESHOLD) * 8
  } else {
    return (consistencyScore - SCORE_CONFIG.CONSISTENCY_THRESHOLD) * 12
  }
}

function calculateObjectivityBonus(
  _dimensions: DimensionScore[],
  qualityMetrics: QualityMetrics
): number {
  const objectivityScore = qualityMetrics.objectivity
  const reliabilityScore = qualityMetrics.reliability

  if (reliabilityScore >= SCORE_CONFIG.RELIABILITY_THRESHOLD) {
    return objectivityScore * SCORE_CONFIG.OBJECTIVITY_WEIGHT * 15
  }

  return 0
}

export function convertToLegacyFormat(
  advancedResult: AdvancedScoreResult,
  dimensions: DimensionScore[]
): {
  overallScore: number
  overallAssessment: string
  title: string
  ratingTag: string
  dimensions: { name: string; score: number; description: string }[]
  strengths: string[]
  improvements: string[]
  qualityMetrics?: QualityMetrics
  adjustments?: Record<string, number>
  recommendations?: string[]
} {
  const { finalScore, qualityMetrics, adjustments } = advancedResult

  const strengths: string[] = []
  const improvements: string[] = []

  return {
    overallScore: finalScore,
    title: generateTitleByScore(finalScore),
    ratingTag: generateRatingTag(finalScore),
    dimensions: dimensions.map((dim) => ({
      name: dim.name,
      score: dim.score,
      description: dim.description
    })),
    strengths,
    improvements,
    qualityMetrics,
    adjustments,
    overallAssessment: ''
  }
}

export function generateTitleByScore(score: number): string {
  if (score >= 140) return 'ğŸŒŒ ä¼ ä¸–ç»å…¸'
  if (score >= 130) return 'ğŸ† æ–‡å­¦å·¨åŒ '
  if (score >= 120) return 'ğŸ‘‘ å¤§å¸ˆçº§ä½œå®¶'
  if (score >= 110) return 'ğŸŒŸ æ°å‡ºä½œå®¶'
  if (score >= 100) return 'ğŸ’ ä¼˜ç§€ä½œå®¶'
  if (score >= 90) return 'âœ¨ èµ„æ·±ä½œå®¶'
  if (score >= 80) return 'ğŸ’« æˆç†Ÿä½œå®¶'
  if (score >= 70) return 'ğŸ”¥ çƒ­é—¨å†™æ‰‹'
  if (score >= 60) return 'ğŸ“ å¯é åˆ›ä½œè€…'
  if (score >= 50) return 'ğŸŒˆ æœ‰æ½œåŠ›åˆ›ä½œè€…'
  if (score >= 40) return 'ğŸŒ± å†™ä½œæ–°é”'
  if (score >= 30) return 'ğŸ“š ä¹ ä½œä½œè€…'
  if (score >= 20) return 'ğŸ« å†™ä½œå­¦å¾’'
  return 'ğŸŒ± å†™ä½œæ–°äºº'
}

export function generateRatingTag(score: number): string {
  if (score >= 140) return 'ğŸŒŒ ä¼ ä¸–ç»å…¸ / ä¸æœ½ä¹‹ä½œ'
  if (score >= 130) return 'ğŸ† æ–‡å­¦å·¨ä½œ / å†å²çº§ä½œå“'
  if (score >= 120) return 'ğŸ‘‘ å¤§å¸ˆä¹‹ä½œ / é¡¶å°–ä½œå“'
  if (score >= 110) return 'ğŸŒŸ æ°å‡ºä¹‹ä½œ / ç°è±¡çº§ä½œå“'
  if (score >= 100) return 'ğŸ’ ä¼˜ç§€ä½œå“ / å¸‚åœºçƒ­é—¨'
  if (score >= 90) return 'âœ¨ èµ„æ·±ä½œå“ / å€¼å¾—æ”¶è—'
  if (score >= 80) return 'ğŸ’« æˆç†Ÿä½œå“ / å€¼å¾—ä¸€è¯»'
  if (score >= 70) return 'ğŸ”¥ çƒ­é—¨ä½œå“ / å¼•äººå…¥èƒœ'
  if (score >= 60) return 'ğŸ“ å¯é ä½œå“ / æœ‰äº®ç‚¹'
  if (score >= 50) return 'ğŸŒˆ æœ‰æ½œåŠ› / éœ€è¦æ‰“ç£¨'
  if (score >= 40) return 'ğŸŒ± æ–°é”ä½œå“ / æœ‰å¯èƒ½æ€§'
  if (score >= 30) return 'ğŸ“š ä¹ ä½œä½œå“ / éœ€è¦æ”¹è¿›'
  if (score >= 20) return 'ğŸ« å­¦å¾’ä½œå“ / åˆçº§æ¨¡ä»¿'
  return 'ğŸŒ± å…¥é—¨ä½œå“ / éœ€è¦å­¦ä¹ '
}
